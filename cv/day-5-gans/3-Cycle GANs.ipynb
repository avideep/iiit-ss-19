{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3: Cycle GAN \n",
    "\n",
    "CycleGAN is used to transfer images from one domain to another domain. For example, we can convert pictures of horses to zebras and back. We can also colourize gray images. There are a lot of exciting applications for this type of GAN.\n",
    "\n",
    "<img src='Images/Cycle.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define some constants and convenience functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import scipy.ndimage.interpolation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "device = torch.device('cuda')\n",
    "#%matplotlib inline\n",
    "\n",
    "mb_size = 128\n",
    "Z_dim = 100\n",
    "X_dim = 784\n",
    "y_dim = 10\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-4\n",
    "lambda_idt = 0.1\n",
    "\n",
    "def plotgrid(img):\n",
    "    img = img.view([mb_size,1,28,28])\n",
    "    img = torchvision.utils.make_grid(img)\n",
    "    img = img.permute(1,2,0)\n",
    "    plt.imshow(img.detach().numpy())\n",
    "    \n",
    "def log(x):\n",
    "    return torch.log(x + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the dataset. We are using MNIST here. Since CycleGAN converts between two domains, we will use normal MNIST for one domain. For the other domain, we will use transposed MNIST. We are basically trying to make the network learn the transpose operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = './data'\n",
    "\n",
    "# load the dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0,), (1,))])\n",
    "trainset = torchvision.datasets.MNIST(root=dataroot , train=False, download=True,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=mb_size,shuffle=True, num_workers=2)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "def mnist_next(diter):\n",
    "\n",
    "    try:\n",
    "        images, labels = diter.next()\n",
    "        if images.shape[0]!=mb_size:\n",
    "            diter = initialize_loader(trainset)\n",
    "            images, labels = diter.next()\n",
    "        images = images.view(images.numpy().shape[0],28*28)\n",
    "    except:\n",
    "        diter = iter(trainloader)\n",
    "        images, labels = diter.next()\n",
    "        if images.shape[0]!=mb_size:\n",
    "            diter = initialize_loader(trainset)\n",
    "            images, labels = diter.next()\n",
    "        images = images.view(images.numpy().shape[0],28*28)\n",
    "    return images, labels\n",
    "\n",
    "def mnist_next2(diter):\n",
    "\n",
    "    try:\n",
    "        images, labels = diter.next()\n",
    "        if images.shape[0]!=mb_size:\n",
    "            diter = initialize_loader(trainset)\n",
    "            images, labels = diter.next()\n",
    "        images = images.permute(0,1,3,2)\n",
    "        images = images.contiguous().view(images.numpy().shape[0],28*28)\n",
    "    except:\n",
    "        diter = iter(trainloader)\n",
    "        images, labels = diter.next()\n",
    "        if images.shape[0]!=mb_size:\n",
    "            diter = initialize_loader(trainset)\n",
    "            images, labels = diter.next()\n",
    "        images = images.permute(0,1,3,2)\n",
    "        images = images.contiguous().view(images.numpy().shape[0],28*28)\n",
    "    return images, labels\n",
    "\n",
    "def initialize_loader(trainset):\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=mb_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "    dataiter = iter(trainloader)\n",
    "    return dataiter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the networks. For CycleGAN, there are two generators, and two discriminators.\n",
    "<img src='Images/CGAN.jpg'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_AB = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim, h_dim),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h_dim, X_dim),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "G_BA = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim, h_dim),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h_dim, X_dim),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "D_A = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim, h_dim),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(h_dim, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "D_B = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim, h_dim),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(h_dim, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "nets = [G_AB, G_BA, D_A, D_B]\n",
    "G_params = list(G_AB.parameters()) + list(G_BA.parameters())\n",
    "D_params = list(D_A.parameters()) + list(D_B.parameters())\n",
    "\n",
    "\n",
    "def reset_grad():\n",
    "    for net in nets:\n",
    "        net.zero_grad()\n",
    "\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=lr)\n",
    "D_solver = optim.Adam(D_params, lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer all of it to the gpu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_AB.to(device)\n",
    "G_BA.to(device)\n",
    "D_A.to(device)\n",
    "D_B.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us train the dataset. Both the generators and discriminators are trained at one go.\n",
    "<img src='Images/cyclegan.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; D_loss: 2.848; G_loss: 402.2\n",
      "Iter-1000; D_loss: 1.425; G_loss: 98.59\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for it in range(5000):\n",
    "    # Sample data from both domains\n",
    "    X_A= mnist_next(dataiter)[0];\n",
    "    X_B = mnist_next2(dataiter)[0];\n",
    "    X_A = X_A.to(device)\n",
    "    X_B = X_B.to(device)\n",
    "    \n",
    "    # Discriminator A\n",
    "    X_BA = G_BA(X_B)\n",
    "    D_A_real = D_A(X_A)\n",
    "    D_A_fake = D_A(X_BA)\n",
    "\n",
    "    L_D_A = -torch.mean(log(D_A_real) + log(1 - D_A_fake))\n",
    "\n",
    "    # Discriminator B\n",
    "    X_AB = G_AB(X_A)\n",
    "    D_B_real = D_B(X_B)\n",
    "    D_B_fake = D_B(X_AB)\n",
    "\n",
    "    L_D_B = -torch.mean(log(D_B_real) + log(1 - D_B_fake))\n",
    "\n",
    "    # Total discriminator loss\n",
    "    D_loss = L_D_A + L_D_B\n",
    "\n",
    "    D_loss.backward()\n",
    "    D_solver.step()\n",
    "    reset_grad()\n",
    "\n",
    "    # Generator AB\n",
    "    X_AB = G_AB(X_A)\n",
    "    D_B_fake = D_B(X_AB)\n",
    "    X_ABA = G_BA(X_AB)\n",
    "    \n",
    "    L_adv_B = -torch.mean(log(D_B_fake))\n",
    "    L_loss_cycle_A = torch.mean(torch.sum((X_A - X_ABA)**2, 1))\n",
    "    #L_G_AB = L_adv_B + L_loss_cycle_A\n",
    "\n",
    "    # Generator BA\n",
    "    X_BA = G_BA(X_B)\n",
    "    D_A_fake = D_A(X_BA)\n",
    "    X_BAB = G_AB(X_BA)\n",
    "\n",
    "    L_adv_A = -torch.mean(log(D_A_fake))\n",
    "    L_loss_cycle_B = torch.mean(torch.sum((X_B - X_BAB)**2, 1))\n",
    "    #L_G_BA = L_adv_A + L_loss_cycle_B\n",
    "    \n",
    "    L_G = L_adv_B + L_adv_A\n",
    "    L_cycle = L_loss_cycle_A + L_loss_cycle_B\n",
    "    # Identity loss\n",
    "    \n",
    "    # G_A2B(B) should equal B if real B is fed\n",
    "    same_B = G_AB(X_B)\n",
    "    loss_identity_B = torch.mean( torch.sum((X_B - same_B)**2, 1))\n",
    "    \n",
    "    # G_B2A(A) should equal A if real A is fed\n",
    "    same_A = G_BA(X_A)\n",
    "    loss_identity_A = torch.mean(torch.sum((X_A - same_A)**2, 1))\n",
    "    Identity_loss = lambda_idt*(loss_identity_B + loss_identity_A)\n",
    "    \n",
    "    # Total generator loss\n",
    "    G_loss = L_G + L_cycle + Identity_loss\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {:.4}; G_loss: {:.4}'.format(it, D_loss.item(), G_loss.item()))\n",
    "        cnt += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what the trained networks produce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = torch.tensor(mnist_next(dataiter )[0])\n",
    "input_B = torch.tensor(mnist_next2(dataiter)[0])\n",
    "\n",
    "samples_A = G_BA(input_B.to(device))\n",
    "samples_B = G_AB(input_A.to(device))\n",
    "samples_A = samples_A.cpu()\n",
    "samples_B = samples_B.cpu()\n",
    "\n",
    "plotgrid(input_B)\n",
    "plt.show()\n",
    "plotgrid(samples_A)\n",
    "plt.show()\n",
    "plotgrid(input_A)\n",
    "plt.show()\n",
    "plotgrid(samples_B)\n",
    "\n",
    "\n",
    "\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points to ponder\n",
    "1. Observe the ouput without cycle consistency loss ?\n",
    "2. What happens when 'lambda_idt' is change to 10 ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
